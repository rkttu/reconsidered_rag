# AI Pack - Semantic Chunking with BGE-M3

[![License](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://opensource.org/licenses/Apache-2.0)
[![Python](https://img.shields.io/badge/Python-3.11%2B-blue.svg)](https://www.python.org/)
[![MCP](https://img.shields.io/badge/MCP-Compatible-green.svg)](https://modelcontextprotocol.io/)

A semantic chunking tool using the BGE-M3 embedding model.  
Converts documents of various formats to Markdown, splits them based on semantic meaning, and preserves heading hierarchy.

## Project Concept

> Basecamp for various RAG extensions + Simple preview

aipack provides a foundation for vector RAG while serving as a starting point for extensions like graph RAG and hybrid RAG:

- **Basecamp Role**: Parquet files act as "extension hubs" for easy migration to various backends like Milvus, Qdrant, Memgraph
- **Preview Role**: MCP server enables testing/prototyping before building full RAG applications
- **Database Neutrality**: Not tied to specific vector DBs, flexible expansion based on parquet
- **Incremental Updates**: Flexible response to changes in embedding models or source content

## Architecture

```mermaid
flowchart TD
    subgraph "Input"
        A[input_docs/<br/>Various format documents]
    end
    
    subgraph "Preprocessing"
        B[02_prepare_content.py<br/>Metadata extraction<br/>Markdown conversion]
    end
    
    subgraph "Chunking"
        C[03_semantic_chunking.py<br/>Semantic chunking<br/>Embedding generation]
    end
    
    subgraph "Storage"
        D[chunked_data/<br/>parquet files]
    end
    
    subgraph "Vector DB"
        E[04_build_vector_db.py<br/>sqlite-vec build]
    end
    
    subgraph "Serving"
        F[05_mcp_server.py<br/>MCP server<br/>Vector search + reranking]
    end
    
    A --> B
    B --> C
    C --> D
    D --> E
    E --> F
    
    style A fill:#e1f5fe
    style B fill:#f3e5f5
    style C fill:#e8f5e8
    style D fill:#fff3e0
    style E fill:#fce4ec
    style F fill:#e0f2f1
```

Intermediate results from each step are saved as parquet files, making various experiments and external system migrations easy.

## Features

- **Support for Various Document Formats**: Using Microsoft markitdown
  - Office documents: Word (.docx), Excel (.xlsx), PowerPoint (.pptx)
  - PDF, HTML, XML, JSON, CSV
  - Images (EXIF/OCR), Audio (speech recognition), Video (subtitle extraction)
  - Code files, Jupyter Notebook, ZIP archives
- **Microsoft Foundry Service Integration** (Optional)
  - Document Intelligence: Enhanced OCR for scanned PDFs and images
  - Azure OpenAI (GPT-4o): Image content understanding
  - Only configured services are automatically activated
- **Semantic Chunking**: Chunk splitting based on semantic similarity
- **Markdown Structure Preservation**: Maintains hierarchical information like heading levels and section paths
- **Multilingual Support**: BGE-M3's support for 100+ languages
- **Incremental Updates**: Change detection based on content hash
- **zstd Compression**: Efficient parquet storage
- **BGE Reranker**: Reranking support for improved search result accuracy
- **CPU-Friendly**: Works without GPU (automatically uses GPU if available)

## Supported File Formats

| Category | Extensions |
| -------- | ---------- |
| Office Documents | `.docx`, `.doc`, `.xlsx`, `.xls`, `.pptx`, `.ppt` |
| PDF/Web | `.pdf`, `.html`, `.htm`, `.xml`, `.json`, `.csv` |
| Markdown/Text | `.md`, `.markdown`, `.txt`, `.rst` |
| Images (EXIF/OCR) | `.jpg`, `.jpeg`, `.png`, `.gif`, `.bmp`, `.webp`, `.tiff` |
| Audio (Speech Recognition) | `.mp3`, `.wav`, `.m4a`, `.ogg`, `.flac` |
| Video (Subtitle Extraction) | `.mp4`, `.mkv`, `.avi`, `.mov`, `.webm` |
| Code/Other | `.py`, `.js`, `.ts`, `.java`, `.c`, `.cpp`, `.ipynb`, `.zip` |

## Module Structure

| Module | Description |
| ------ | ----------- |
| `01_download_model.py` | BGE-M3 embedding model and reranker model download |
| `02_prepare_content.py` | Metadata extraction and YAML front matter generation |
| `03_semantic_chunking.py` | Semantic chunking and parquet storage |
| `04_build_vector_db.py` | sqlite-vec vector DB build and search |
| `05_mcp_server.py` | MCP server (stdio/SSE mode support) |

## Installation

### Installing uv

uv is a fast Python package manager. Install it from the official repository:

**Windows (PowerShell):**

```powershell
powershell -c "irm https://astral.sh/uv/install.ps1 | iex"
```

**Linux/macOS:**

```bash
curl -LsSf https://astral.sh/uv/install.sh | sh
```

Or install via pip:

```bash
pip install uv
```

For more installation options, visit: <https://github.com/astral-sh/uv>.

### Installing Dependencies

```bash
# Using uv (recommended)
uv sync

# Or using pip
pip install FlagEmbedding mistune pyarrow pandas pyyaml markitdown[all]
```

> **Note**: The `huggingface-hub[hf_xet]` package is included to improve download speeds for Xet Storage-supported models.

## Containerization

The program can be containerized using Docker. Model files are mounted as host volumes for caching.

### Build and Run

```bash
# Build image
docker-compose build

# Run (automatic model download â†’ data processing â†’ server start)
docker-compose up

# Or stdio mode
docker-compose run --rm aipack ./entrypoint.sh

# Specify port
PORT=9090 docker-compose up
```

### Execution Flow

The container automatically performs the following steps on startup:

1. **Model Download**: Check cache and download BGE-M3 and reranker models
2. **Data Processing**: If `input_docs/` exists, prepare documents â†’ chunking â†’ vector DB build
3. **Server Start**: Run MCP server (SSE mode by default)

> **Note**: Works even in environments without uv or Python runtime (multi-stage build)

### Volume Mounts

- **Model Cache**: `./cache/huggingface` â†’ `/root/.cache/huggingface` in container
  - Stores large files like BGE-M3 and reranker models in project's `cache/` directory
  - Explicit `cache_dir` setting in code controls cache location
  - Cache reuse on container restart saves download time
- **Data Directories**: `input_docs`, `prepared_contents`, `chunked_data`, `vector_db`
  - Data sharing between host and container

### Environment Variables

- `PYTHONUNBUFFERED=1`: Immediate log output

## Microsoft Foundry Service Integration (Optional)

Works with basic markitdown alone, but better results can be achieved by integrating Microsoft Foundry services.

### Supported Services

| Service | Purpose | Enhanced Features |
| ------- | ------- | ----------------- |
| Document Intelligence | Scanned PDF, image OCR | Text extraction accuracy |
| Azure OpenAI (GPT-4o) | Image content understanding | Image description generation |

### Configuration

```bash
# 1. Create environment file
cp .env.example .env

# 2. Enter only necessary keys (only configured services are activated)
```

Example `.env` file:

```env
# Document Intelligence (scanned PDF, image OCR)
AZURE_DOCUMENT_INTELLIGENCE_ENDPOINT=https://your-resource.cognitiveservices.azure.com/
AZURE_DOCUMENT_INTELLIGENCE_KEY=your-key

# Azure OpenAI (image content understanding)
AZURE_OPENAI_ENDPOINT=https://your-openai.openai.azure.com/
AZURE_OPENAI_API_KEY=your-key
AZURE_OPENAI_DEPLOYMENT_NAME=gpt-4o
```

### Operation

- **No Keys**: Uses basic markitdown only
- **Some Services Configured**: Only those services are activated
- **All Configured**: Full functionality activated

Integration status is displayed during execution:

```text
ğŸ”— Azure services integrated: Document Intelligence, OpenAI (gpt-4o)
```

Or:

```text
â„¹ï¸ Azure services not integrated (using basic markitdown)
```

## Usage

### 1. Model Download (One-time)

```bash
python 01_download_model.py
```

### 2. Document Preparation

Place files in `input_docs/` directory (various formats supported):

```bash
python 02_prepare_content.py
```

All supported file formats are converted to Markdown with metadata added.

### 3. Semantic Chunking

```bash
python 03_semantic_chunking.py
```

Options:

- `--input-dir`: Input directory (default: `prepared_contents`)
- `--output-dir`: Output directory (default: `chunked_data`)
- `--similarity-threshold`: Similarity threshold (default: 0.5)

### 4. Vector DB Build

```bash
python 04_build_vector_db.py
```

Options:

- `--input-dir`: Input directory (default: `chunked_data`)
- `--output-dir`: Output directory (default: `vector_db`)
- `--db-name`: DB filename (default: `vectors.db`)
- `--export-parquet`: Export parquet for Milvus/Qdrant migration
- `--test-search "query"`: Perform test search after build

#### Vector DB Portability

Exported parquet files (`vectors_export.parquet`) can be directly imported to the following vector DBs:

| Vector DB | Import Method |
| --------- | ------------- |
| **Milvus** | Direct import using `pymilvus`'s `insert()` method |
| **Qdrant** | Upsert via REST API or Python client |
| **Pinecone** | Direct import using `upsert()` method |
| **Chroma** | Direct import using `add()` method |

Vector format: `float32[1024]` (BGE-M3 Dense vectors)

### 5. MCP Server Execution

Provides vector search via MCP protocol.

#### stdio Mode (Claude Desktop, Cursor, etc.)

```bash
python 05_mcp_server.py
```

#### SSE Mode (Web clients)

```bash
python 05_mcp_server.py --sse --port 8080
```

Options:

- `--db-path`: Vector DB path (default: `vector_db/vectors.db`)
- `--sse`: Run in SSE mode
- `--host`: SSE server host (default: `127.0.0.1`)
- `--port`: SSE server port (default: `8080`)

#### Available Tools

| Tool | Description |
| ---- | ----------- |
| `search` | Vector similarity search + reranking |
| `get_chunk` | Detailed lookup by chunk ID |
| `list_documents` | Document list lookup |
| `get_stats` | DB statistics lookup |

#### Claude Desktop Configuration Example

`claude_desktop_config.json`:

```json
{
  "mcpServers": {
    "aipack-vector-search": {
      "command": "python",
      "args": ["D:/Projects/aipack/05_mcp_server.py"]
    }
  }
}
```

## Output Schema

| Field | Type | Description |
| ----- | ---- | ----------- |
| `chunk_id` | string | Unique chunk ID |
| `content_hash` | string | Content hash (for incremental updates) |
| `chunk_text` | string | Chunk text |
| `chunk_type` | string | Type (header, paragraph, list, code, table) |
| `heading_level` | int32 | Heading level (0=normal, 1-6=H1-H6) |
| `heading_text` | string | Current heading text |
| `parent_heading` | string | Parent heading text |
| `section_path` | list[string] | Section hierarchy path array |
| `table_headers` | list[string] | Table column headers (if table) |
| `table_row_count` | int32 | Table data row count (if table) |
| `domain` | string | Domain (metadata) |
| `keywords` | string | Keywords JSON (metadata) |
| `version` | int32 | Version number |

## Directory Structure

```text
aipack/
â”œâ”€â”€ 01_download_model.py       # BGE-M3 model download
â”œâ”€â”€ 02_prepare_content.py      # Metadata extraction + Azure integration
â”œâ”€â”€ 03_semantic_chunking.py    # Semantic chunking
â”œâ”€â”€ 04_build_vector_db.py      # Vector DB build
â”œâ”€â”€ 05_mcp_server.py           # MCP server (stdio/SSE)
â”œâ”€â”€ input_docs/                # Input documents
â”œâ”€â”€ prepared_contents/         # Documents with metadata added
â”œâ”€â”€ chunked_data/              # Chunked parquet files
â”œâ”€â”€ vector_db/                 # sqlite-vec vector DB
â”‚   â”œâ”€â”€ vectors.db             # Local vector DB
â”‚   â””â”€â”€ vectors_export.parquet # Export file for migration
â”œâ”€â”€ .env.example               # Environment variable template
â”œâ”€â”€ pyproject.toml
â””â”€â”€ README.md
```

## Examples

### Input Markdown

```markdown
# Title

## Section 1
Content...

## Section 2
Other content...
```

### Output Parquet Example

| chunk_id | heading_level | heading_text | section_path |
| -------- | ------------- | ------------ | ------------ |
| abc123 | 1 | Title | # Title |
| def456 | 2 | Section 1 | # Title / ## Section 1 |
| ghi789 | 2 | Section 2 | # Title / ## Section 2 |

## System Requirements

- Python 3.11+
- ~5GB disk space (for BGE-M3 + reranker models)
- 8GB+ RAM recommended
- GPU (optional): Automatically utilized if CUDA-compatible GPU available

## Future Extension Possibilities

The current system is designed with the following extensions in mind:

| Extension Direction | Description | Current Status |
| ------------------- | ----------- | -------------- |
| **Graph RAG** | Ontology-based entity/relation extraction â†’ Node/edge parquet generation | Design completed |
| **Hybrid Search** | Combination of keyword + vector + graph search | Vector + reranking implemented |
| **Homonym Handling** | Context distinction via domain-specific ontology mapping | Metadata-based |
| **Multiple Vector DBs** | Migration to Milvus, Qdrant, Pinecone, etc. | Parquet export supported |

## Contributing

1. Fork this repository.
2. Create a new branch: `git checkout -b feature/amazing-feature`
3. Commit your changes: `git commit -m 'Add amazing feature'`
4. Push to the branch: `git push origin feature/amazing-feature`
5. Create a Pull Request.

## License

This project is licensed under the [Apache License 2.0](LICENSE).

## ëª¨ë“ˆ êµ¬ì„±

| ëª¨ë“ˆ | ì„¤ëª… |
| ------ | ------ |
| `01_download_model.py` | BGE-M3 ì„ë² ë”© ëª¨ë¸ ë° ë¦¬ë­ì»¤ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ |
| `02_prepare_content.py` | ë©”íƒ€ë°ì´í„° ì¶”ì¶œ ë° YAML front matter ìƒì„± |
| `03_semantic_chunking.py` | ì‹œë§¨í‹± ì²­í‚¹ ë° parquet ì €ì¥ |
| `04_build_vector_db.py` | sqlite-vec ë²¡í„° DB ë¹Œë“œ ë° ê²€ìƒ‰ |
| `05_mcp_server.py` | MCP ì„œë²„ (stdio/SSE ëª¨ë“œ ì§€ì›) |

## ì„¤ì¹˜

```bash
# uv ì‚¬ìš© (ê¶Œì¥)
uv sync

# ë˜ëŠ” pip
pip install FlagEmbedding mistune pyarrow pandas pyyaml markitdown[all]
```

> **ì°¸ê³ **: `huggingface-hub[hf_xet]` íŒ¨í‚¤ì§€ê°€ í¬í•¨ë˜ì–´ ìˆì–´, Xet Storage ì§€ì› ëª¨ë¸ì˜ ë‹¤ìš´ë¡œë“œ ì†ë„ê°€ í–¥ìƒë©ë‹ˆë‹¤.

## ì»¨í…Œì´ë„ˆí™”

Dockerë¥¼ ì‚¬ìš©í•˜ì—¬ í”„ë¡œê·¸ë¨ì„ ì»¨í…Œì´ë„ˆí™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ëª¨ë¸ íŒŒì¼ì€ í˜¸ìŠ¤íŠ¸ ë³¼ë¥¨ìœ¼ë¡œ ë§ˆìš´íŠ¸í•˜ì—¬ ìºì‹œí•©ë‹ˆë‹¤.

### ë¹Œë“œ ë° ì‹¤í–‰

```bash
# ì´ë¯¸ì§€ ë¹Œë“œ
docker-compose build

# ì‹¤í–‰ (ìë™ìœ¼ë¡œ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ â†’ ë°ì´í„° ì²˜ë¦¬ â†’ ì„œë²„ ì‹œì‘)
docker-compose up

# ë˜ëŠ” stdio ëª¨ë“œ
docker-compose run --rm aipack ./entrypoint.sh

# í¬íŠ¸ ì§€ì •
PORT=9090 docker-compose up
```

### ì‹¤í–‰ íë¦„

ì»¨í…Œì´ë„ˆ ì‹œì‘ ì‹œ ìë™ìœ¼ë¡œ ë‹¤ìŒ ë‹¨ê³„ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤:

1. **ëª¨ë¸ ë‹¤ìš´ë¡œë“œ**: ìºì‹œ í™•ì¸ í›„ BGE-M3 ë° ë¦¬ë­ì»¤ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ
2. **ë°ì´í„° ì²˜ë¦¬**: `input_docs/` ì¡´ì¬ ì‹œ ë¬¸ì„œ ì¤€ë¹„ â†’ ì²­í‚¹ â†’ ë²¡í„° DB ë¹Œë“œ
3. **ì„œë²„ ì‹œì‘**: MCP ì„œë²„ ì‹¤í–‰ (SSE ëª¨ë“œ ê¸°ë³¸)

> **ì°¸ê³ **: uvë‚˜ Python ëŸ°íƒ€ì„ì´ ì—†ëŠ” í™˜ê²½ì—ì„œë„ ì‹¤í–‰ ê°€ëŠ¥ (ë©€í‹°ìŠ¤í…Œì´ì§€ ë¹Œë“œ)

### ë³¼ë¥¨ ë§ˆìš´íŠ¸

- **ëª¨ë¸ ìºì‹œ**: `./cache/huggingface` â†’ ì»¨í…Œì´ë„ˆ ë‚´ `/root/.cache/huggingface`
  - BGE-M3, ë¦¬ë­ì»¤ ëª¨ë¸ ë“± ëŒ€ìš©ëŸ‰ íŒŒì¼ì„ í”„ë¡œì íŠ¸ ë‚´ `cache/` ë””ë ‰í„°ë¦¬ì— ì €ì¥
  - ì½”ë“œì—ì„œ ëª…ì‹œì ìœ¼ë¡œ `cache_dir` ì„¤ì •í•˜ì—¬ ìºì‹œ ìœ„ì¹˜ ì œì–´
  - ì»¨í…Œì´ë„ˆ ì¬ì‹œì‘ ì‹œ ìºì‹œ ì¬ì‚¬ìš©, ë‹¤ìš´ë¡œë“œ ì‹œê°„ ì ˆì•½
- **ë°ì´í„° ë””ë ‰í„°ë¦¬**: `input_docs`, `prepared_contents`, `chunked_data`, `vector_db`
  - í˜¸ìŠ¤íŠ¸ì™€ ì»¨í…Œì´ë„ˆ ê°„ ë°ì´í„° ê³µìœ 

### í™˜ê²½ ë³€ìˆ˜

- `PYTHONUNBUFFERED=1`: ë¡œê·¸ ì¶œë ¥ ì¦‰ì‹œ í‘œì‹œ

## Microsoft Foundry ì„œë¹„ìŠ¤ ì—°ë™ (ì„ íƒì‚¬í•­)

ê¸°ë³¸ markitdownë§Œìœ¼ë¡œë„ ë™ì‘í•˜ì§€ë§Œ, Microsoft Foundry ì„œë¹„ìŠ¤ë¥¼ ì—°ë™í•˜ë©´ ë” ë‚˜ì€ ê²°ê³¼ë¥¼ ì–»ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

### ì§€ì› ì„œë¹„ìŠ¤

| ì„œë¹„ìŠ¤ | ìš©ë„ | í–¥ìƒë˜ëŠ” ê¸°ëŠ¥ |
| ------ | ------ | ------ |
| Document Intelligence | ìŠ¤ìº” PDF, ì´ë¯¸ì§€ OCR | í…ìŠ¤íŠ¸ ì¶”ì¶œ ì •í™•ë„ |
| Azure OpenAI (GPT-4o) | ì´ë¯¸ì§€ ë‚´ìš© ì´í•´ | ì´ë¯¸ì§€ ì„¤ëª… ìƒì„± |

### ì„¤ì • ë°©ë²•

```bash
# 1. í™˜ê²½ íŒŒì¼ ìƒì„±
cp .env.example .env

# 2. í•„ìš”í•œ í‚¤ë§Œ ì…ë ¥ (ì„¤ì •ëœ ì„œë¹„ìŠ¤ë§Œ í™œì„±í™”ë¨)
```

`.env` íŒŒì¼ ì˜ˆì‹œ:

```env
# Document Intelligence (ìŠ¤ìº” PDF, ì´ë¯¸ì§€ OCR)
AZURE_DOCUMENT_INTELLIGENCE_ENDPOINT=https://your-resource.cognitiveservices.azure.com/
AZURE_DOCUMENT_INTELLIGENCE_KEY=your-key

# Azure OpenAI (ì´ë¯¸ì§€ ë‚´ìš© ì´í•´)
AZURE_OPENAI_ENDPOINT=https://your-openai.openai.azure.com/
AZURE_OPENAI_API_KEY=your-key
AZURE_OPENAI_DEPLOYMENT_NAME=gpt-4o
```

### ë™ì‘ ë°©ì‹

- **í‚¤ ì—†ìŒ**: ê¸°ë³¸ markitdownë§Œ ì‚¬ìš©
- **ì¼ë¶€ ì„œë¹„ìŠ¤ë§Œ ì„¤ì •**: í•´ë‹¹ ì„œë¹„ìŠ¤ë§Œ í™œì„±í™”
- **ëª¨ë‘ ì„¤ì •**: ì „ì²´ ê¸°ëŠ¥ í™œì„±í™”

ì‹¤í–‰ ì‹œ ì—°ë™ ìƒíƒœê°€ í‘œì‹œë©ë‹ˆë‹¤:

```text
ğŸ”— Azure ì„œë¹„ìŠ¤ ì—°ë™: Document Intelligence, OpenAI (gpt-4o)
```

ë˜ëŠ”:

```text
â„¹ï¸ Azure ì„œë¹„ìŠ¤ ë¯¸ì—°ë™ (ê¸°ë³¸ markitdown ì‚¬ìš©)
```

## ì‚¬ìš©ë²•

### 1. ëª¨ë¸ ë‹¤ìš´ë¡œë“œ (ìµœì´ˆ 1íšŒ)

```bash
python 01_download_model.py
```

### 2. ë¬¸ì„œ ì¤€ë¹„

`input_docs/` ë””ë ‰í„°ë¦¬ì— íŒŒì¼ì„ ë„£ê³  (ë‹¤ì–‘í•œ í˜•ì‹ ì§€ì›):

```bash
python 02_prepare_content.py
```

ì§€ì›ë˜ëŠ” ëª¨ë“  í˜•ì‹ì˜ íŒŒì¼ì´ ë§ˆí¬ë‹¤ìš´ìœ¼ë¡œ ë³€í™˜ë˜ê³  ë©”íƒ€ë°ì´í„°ê°€ ì¶”ê°€ë©ë‹ˆë‹¤.

### 3. ì‹œë§¨í‹± ì²­í‚¹

```bash
python 03_semantic_chunking.py
```

ì˜µì…˜:

- `--input-dir`: ì…ë ¥ ë””ë ‰í„°ë¦¬ (ê¸°ë³¸: `prepared_contents`)
- `--output-dir`: ì¶œë ¥ ë””ë ‰í„°ë¦¬ (ê¸°ë³¸: `chunked_data`)
- `--similarity-threshold`: ìœ ì‚¬ë„ ì„ê³„ê°’ (ê¸°ë³¸: 0.5)

### 4. ë²¡í„° DB ë¹Œë“œ

```bash
python 04_build_vector_db.py
```

ì˜µì…˜:

- `--input-dir`: ì…ë ¥ ë””ë ‰í„°ë¦¬ (ê¸°ë³¸: `chunked_data`)
- `--output-dir`: ì¶œë ¥ ë””ë ‰í„°ë¦¬ (ê¸°ë³¸: `vector_db`)
- `--db-name`: DB íŒŒì¼ëª… (ê¸°ë³¸: `vectors.db`)
- `--export-parquet`: Milvus/Qdrant ì´ì‹ìš© Parquet ë‚´ë³´ë‚´ê¸°
- `--test-search "ì¿¼ë¦¬"`: ë¹Œë“œ í›„ í…ŒìŠ¤íŠ¸ ê²€ìƒ‰ ìˆ˜í–‰

#### ë²¡í„° DB ì´ì‹ì„±

ë‚´ë³´ë‚´ê¸°ëœ Parquet íŒŒì¼(`vectors_export.parquet`)ì€ ë‹¤ìŒ ë²¡í„° DBë¡œ ì§ì ‘ ì´ì‹ ê°€ëŠ¥:

| ë²¡í„° DB | ì´ì‹ ë°©ë²• |
| ------ | ------ |
| **Milvus** | `pymilvus`ì˜ `insert()` ë©”ì„œë“œë¡œ ì§ì ‘ import |
| **Qdrant** | REST API ë˜ëŠ” Python í´ë¼ì´ì–¸íŠ¸ë¡œ upsert |
| **Pinecone** | `upsert()` ë©”ì„œë“œë¡œ ì§ì ‘ import |
| **Chroma** | `add()` ë©”ì„œë“œë¡œ ì§ì ‘ import |

ë²¡í„° í˜•ì‹: `float32[1024]` (BGE-M3 Dense ë²¡í„°)

### 5. MCP ì„œë²„ ì‹¤í–‰

ë²¡í„° ê²€ìƒ‰ì„ MCP í”„ë¡œí† ì½œë¡œ ì œê³µí•©ë‹ˆë‹¤.

#### stdio ëª¨ë“œ (Claude Desktop, Cursor ë“±)

```bash
python 05_mcp_server.py
```

#### SSE ëª¨ë“œ (ì›¹ í´ë¼ì´ì–¸íŠ¸)

```bash
python 05_mcp_server.py --sse --port 8080
```

ì˜µì…˜:

- `--db-path`: ë²¡í„° DB ê²½ë¡œ (ê¸°ë³¸: `vector_db/vectors.db`)
- `--sse`: SSE ëª¨ë“œë¡œ ì‹¤í–‰
- `--host`: SSE ì„œë²„ í˜¸ìŠ¤íŠ¸ (ê¸°ë³¸: `127.0.0.1`)
- `--port`: SSE ì„œë²„ í¬íŠ¸ (ê¸°ë³¸: `8080`)

#### ì œê³µ ë„êµ¬ (Tools)

| ë„êµ¬ | ì„¤ëª… |
| ------ | ------ |
| `search` | ë²¡í„° ìœ ì‚¬ë„ ê²€ìƒ‰ + ë¦¬ë­í‚¹ |
| `get_chunk` | ì²­í¬ IDë¡œ ìƒì„¸ ì¡°íšŒ |
| `list_documents` | ë¬¸ì„œ ëª©ë¡ ì¡°íšŒ |
| `get_stats` | DB í†µê³„ ì¡°íšŒ |

#### Claude Desktop ì„¤ì • ì˜ˆì‹œ

`claude_desktop_config.json`:

```json
{
  "mcpServers": {
    "aipack-vector-search": {
      "command": "python",
      "args": ["D:/Projects/aipack/05_mcp_server.py"]
    }
  }
}
```

## ì¶œë ¥ ìŠ¤í‚¤ë§ˆ

| í•„ë“œ | íƒ€ì… | ì„¤ëª… |
| ------ | ------ | ------ |
| `chunk_id` | string | ì²­í¬ ê³ ìœ  ID |
| `content_hash` | string | ì½˜í…ì¸  í•´ì‹œ (ì¦ë¶„ ì—…ë°ì´íŠ¸ìš©) |
| `chunk_text` | string | ì²­í¬ í…ìŠ¤íŠ¸ |
| `chunk_type` | string | íƒ€ì… (header, paragraph, list, code, table) |
| `heading_level` | int32 | í—¤ë”© ë ˆë²¨ (0=ì¼ë°˜, 1-6=H1-H6) |
| `heading_text` | string | í˜„ì¬ í—¤ë”© í…ìŠ¤íŠ¸ |
| `parent_heading` | string | ë¶€ëª¨ í—¤ë”© í…ìŠ¤íŠ¸ |
| `section_path` | list[string] | ì„¹ì…˜ ê³„ì¸µ ê²½ë¡œ ë°°ì—´ |
| `table_headers` | list[string] | í‘œ ì»¬ëŸ¼ í—¤ë” (í‘œì¸ ê²½ìš°) |
| `table_row_count` | int32 | í‘œ ë°ì´í„° í–‰ ìˆ˜ (í‘œì¸ ê²½ìš°) |
| `domain` | string | ë„ë©”ì¸ (ë©”íƒ€ë°ì´í„°) |
| `keywords` | string | í‚¤ì›Œë“œ JSON (ë©”íƒ€ë°ì´í„°) |
| `version` | int32 | ë²„ì „ ë²ˆí˜¸ |

## ë””ë ‰í„°ë¦¬ êµ¬ì¡°

```text
aipack/
â”œâ”€â”€ 01_download_model.py       # BGE-M3 ëª¨ë¸ ë‹¤ìš´ë¡œë“œ
â”œâ”€â”€ 02_prepare_content.py      # ë©”íƒ€ë°ì´í„° ì¶”ì¶œ + Azure ì—°ë™
â”œâ”€â”€ 03_semantic_chunking.py    # ì‹œë§¨í‹± ì²­í‚¹
â”œâ”€â”€ 04_build_vector_db.py      # ë²¡í„° DB ë¹Œë“œ
â”œâ”€â”€ 05_mcp_server.py           # MCP ì„œë²„ (stdio/SSE)
â”œâ”€â”€ input_docs/                # ì…ë ¥ ë¬¸ì„œ
â”œâ”€â”€ prepared_contents/         # ë©”íƒ€ë°ì´í„° ì¶”ê°€ëœ ë¬¸ì„œ
â”œâ”€â”€ chunked_data/              # ì²­í‚¹ëœ parquet íŒŒì¼
â”œâ”€â”€ vector_db/                 # sqlite-vec ë²¡í„° DB
â”‚   â”œâ”€â”€ vectors.db             # ë¡œì»¬ ë²¡í„° DB
â”‚   â””â”€â”€ vectors_export.parquet # ì´ì‹ìš© ë‚´ë³´ë‚´ê¸° íŒŒì¼
â”œâ”€â”€ .env.example               # í™˜ê²½ ë³€ìˆ˜ í…œí”Œë¦¿
â”œâ”€â”€ pyproject.toml
â””â”€â”€ README.md
```

## ì˜ˆì‹œ

### ì…ë ¥ ë§ˆí¬ë‹¤ìš´

```markdown
# ì œëª©

## ì„¹ì…˜ 1
ë‚´ìš©...

## ì„¹ì…˜ 2
ë‹¤ë¥¸ ë‚´ìš©...
```

### ì¶œë ¥ parquet ì˜ˆì‹œ

| chunk_id | heading_level | heading_text | section_path |
| ---------- | --------------- | -------------- | -------------- |
| abc123 | 1 | ì œëª© | # ì œëª© |
| def456 | 2 | ì„¹ì…˜ 1 | # ì œëª© / ## ì„¹ì…˜ 1 |
| ghi789 | 2 | ì„¹ì…˜ 2 | # ì œëª© / ## ì„¹ì…˜ 2 |

## ì‹œìŠ¤í…œ ìš”êµ¬ì‚¬í•­

- Python 3.11 ì´ìƒ
- ì•½ 5GB ë””ìŠ¤í¬ ê³µê°„ (BGE-M3 + ë¦¬ë­ì»¤ ëª¨ë¸ìš©)
- 8GB ì´ìƒ RAM ê¶Œì¥
- GPU (ì„ íƒì‚¬í•­): CUDA ì§€ì› GPUê°€ ìˆìœ¼ë©´ ìë™ìœ¼ë¡œ í™œìš©

## í–¥í›„ í™•ì¥ ê°€ëŠ¥ì„±

í˜„ì¬ ì‹œìŠ¤í…œì€ ë‹¤ìŒê³¼ ê°™ì€ í™•ì¥ì„ ì—¼ë‘ì— ë‘ê³  ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤:

| í™•ì¥ ë°©í–¥ | ì„¤ëª… | í˜„ì¬ ìƒíƒœ |
| -------- | ---- | -------- |
| **ê·¸ë˜í”„ RAG** | ì˜¨í†¨ë¡œì§€ ê¸°ë°˜ ì—”í‹°í‹°/ê´€ê³„ ì¶”ì¶œ â†’ ë…¸ë“œ/ì—£ì§€ parquet ìƒì„± | ì„¤ê³„ ì™„ë£Œ |
| **í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰** | í‚¤ì›Œë“œ + ë²¡í„° + ê·¸ë˜í”„ ê²€ìƒ‰ ê²°í•© | ë²¡í„°+ë¦¬ë­í‚¹ êµ¬í˜„ |
| **ë™ìŒì´ì˜ì–´ ëŒ€ë¹„** | ë„ë©”ì¸ë³„ ì˜¨í†¨ë¡œì§€ ë§¤í•‘ìœ¼ë¡œ ë§¥ë½ êµ¬ë¶„ | ë©”íƒ€ë°ì´í„° ê¸°ë°˜ |
| **ë‹¤ì¤‘ ë²¡í„° DB** | Milvus, Qdrant, Pinecone ë“±ìœ¼ë¡œ ì´ì‹ | parquet export ì§€ì› |

## ê¸°ì—¬ ë°©ë²•

1. ì´ ì €ì¥ì†Œë¥¼ í¬í¬í•©ë‹ˆë‹¤.
2. ìƒˆ ë¸Œëœì¹˜ë¥¼ ìƒì„±í•©ë‹ˆë‹¤: `git checkout -b feature/amazing-feature`
3. ë³€ê²½ ì‚¬í•­ì„ ì»¤ë°‹í•©ë‹ˆë‹¤: `git commit -m 'Add amazing feature'`
4. ë¸Œëœì¹˜ì— í‘¸ì‹œí•©ë‹ˆë‹¤: `git push origin feature/amazing-feature`
5. Pull Requestë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

## ë¼ì´ì„ ìŠ¤

ì´ í”„ë¡œì íŠ¸ëŠ” [Apache License 2.0](LICENSE.md) í•˜ì— ë¼ì´ì„ ìŠ¤ë©ë‹ˆë‹¤.
